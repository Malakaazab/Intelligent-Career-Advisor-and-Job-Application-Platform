{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13458203,"sourceType":"datasetVersion","datasetId":8542796}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers datasets evaluate --quiet\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T17:20:19.885440Z","iopub.execute_input":"2025-12-07T17:20:19.885711Z","iopub.status.idle":"2025-12-07T17:20:23.263422Z","shell.execute_reply.started":"2025-12-07T17:20:19.885686Z","shell.execute_reply":"2025-12-07T17:20:23.262594Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"import os\nimport evaluate\nimport pandas as pd\nfrom datasets import load_dataset, Dataset\nfrom transformers import (\n    AutoTokenizer, \n    AutoModelForSequenceClassification, \n    Trainer, \n    TrainingArguments\n)\n\n# ØªØ¹Ø·ÙŠÙ„ WandB\nos.environ[\"WANDB_MODE\"] = \"disabled\"\n\n# ========== 1. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØªÙ†Ø¸ÙŠÙÙ‡Ø§ ==========\nprint(\" Loading dataset...\")\ndf = pd.read_csv('/kaggle/input/train-csv/train.csv')  # Ù†Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø£ØµÙ„ÙŠ\n\n# Ù†Ø£Ø®Ø° Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ù‡Ù…Ø© Ø¨Ø³\ndf_clean = df[['resume_text', 'job_description_text', 'label']].copy()\n\n# ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù€ labels Ù…Ù† Ù†ØµÙˆØµ Ù„Ø£Ø±Ù‚Ø§Ù…\nlabel_map = {\n    \"No Fit\": 0,\n    \"Potential Fit\": 1,\n    \"Good Fit\": 2\n}\ndf_clean['label'] = df_clean['label'].map(label_map)\n\n# Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ Ù‚ÙŠÙ… ÙØ§Ø±ØºØ©\ndf_clean = df_clean.dropna()\n\nprint(f\"âœ… Label distribution:\")\nprint(df_clean['label'].value_counts().sort_index())\n\n# ØªØ­ÙˆÙŠÙ„ Ù„Ù€ Hugging Face Dataset\ndataset = Dataset.from_pandas(df_clean)\nprint(f\"âœ… Dataset loaded: {len(dataset)} examples\")\n\n# ========== 2. ØªØ­Ù…ÙŠÙ„ JobBERT-v3 ==========\nprint(\"\\nğŸ¤– Loading JobBERT-v3...\")\nmodel_name = \"TechWolf/JobBERT-v3\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    model_name, \n    num_labels=3,\n    ignore_mismatched_sizes=True\n)\nprint(\"âœ… Model loaded successfully!\")\n\n# ========== 3. Tokenization ==========\nprint(\"\\nğŸ”„ Tokenizing dataset...\")\ndef tokenize_function(examples):\n    return tokenizer(\n        examples['resume_text'],\n        examples['job_description_text'],\n        truncation=True,\n        padding='max_length',\n        max_length=256\n    )\n\ntokenized_dataset = dataset.map(\n    tokenize_function, \n    batched=True, \n    remove_columns=['resume_text', 'job_description_text']\n)\nprint(\"âœ… Tokenization complete!\")\n\n# ========== 4. Split Data ==========\ntrain_size = int(0.9 * len(tokenized_dataset))\ntrain_dataset = tokenized_dataset.select(range(train_size))\neval_dataset = tokenized_dataset.select(range(train_size, len(tokenized_dataset)))\nprint(f\"\\nğŸ“Š Train: {len(train_dataset)} | Eval: {len(eval_dataset)}\")\n\n# ========== 5. Metrics ==========\nprint(\"\\nğŸ“ˆ Loading metrics...\")\naccuracy_metric = evaluate.load(\"accuracy\")\nprecision_metric = evaluate.load(\"precision\")\nrecall_metric = evaluate.load(\"recall\")\nf1_metric = evaluate.load(\"f1\")\n\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    preds = logits.argmax(axis=-1)\n    \n    return {\n        \"accuracy\": accuracy_metric.compute(predictions=preds, references=labels)[\"accuracy\"],\n        \"precision\": precision_metric.compute(predictions=preds, references=labels, average=\"weighted\")[\"precision\"],\n        \"recall\": recall_metric.compute(predictions=preds, references=labels, average=\"weighted\")[\"recall\"],\n        \"f1\": f1_metric.compute(predictions=preds, references=labels, average=\"weighted\")[\"f1\"]\n    }\n\n# ========== 6. Training Arguments ==========\ntry:\n    training_args = TrainingArguments(\n        output_dir=\"./jobbert_results\",\n        eval_strategy=\"epoch\",\n        learning_rate=2e-5,\n        per_device_train_batch_size=8,\n        per_device_eval_batch_size=8,\n        num_train_epochs=3,\n        weight_decay=0.01,\n        save_strategy=\"epoch\",\n        logging_steps=50,\n        report_to=\"none\",\n        save_total_limit=2,\n        load_best_model_at_end=True,\n        metric_for_best_model=\"f1\"\n    )\nexcept TypeError:\n    training_args = TrainingArguments(\n        output_dir=\"./jobbert_results\",\n        evaluation_strategy=\"epoch\",\n        learning_rate=2e-5,\n        per_device_train_batch_size=8,\n        per_device_eval_batch_size=8,\n        num_train_epochs=3,\n        weight_decay=0.01,\n        save_strategy=\"epoch\",\n        logging_steps=50,\n        report_to=\"none\",\n        save_total_limit=2,\n        load_best_model_at_end=True,\n        metric_for_best_model=\"f1\"\n    )\n\n# ========== 7. Trainer ==========\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=eval_dataset,\n    compute_metrics=compute_metrics\n)\n\n# ========== 8. Training ==========\nprint(\"\\nğŸš€ Starting JobBERT-v3 Fine-tuning...\")\nprint(\"=\" * 60)\ntrainer.train()\n\n# ========== 9. Evaluation ==========\nprint(\"\\n\" + \"=\" * 60)\nprint(\"ğŸ¯ Evaluating model...\")\neval_result = trainer.evaluate()\n\nprint(\"\\nâœ… Training completed!\")\nprint(\"\\nğŸ“Š Final Results:\")\nprint(\"=\" * 60)\nprint(f\"  Accuracy:  {eval_result['eval_accuracy']:.4f}\")\nprint(f\"  Precision: {eval_result['eval_precision']:.4f}\")\nprint(f\"  Recall:    {eval_result['eval_recall']:.4f}\")\nprint(f\"  F1-Score:  {eval_result['eval_f1']:.4f}\")\nprint(f\"  Loss:      {eval_result['eval_loss']:.4f}\")\nprint(\"=\" * 60)\n\n# ========== 10. Save Model ==========\nprint(\"\\nğŸ’¾ Saving model...\")\nmodel.save_pretrained(\"./jobbert_finetuned\")\ntokenizer.save_pretrained(\"./jobbert_finetuned\")\nprint(\"âœ… Model saved to: ./jobbert_finetuned\")\n\n# ========== 11. Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ==========\nprint(\"\\nğŸ“ˆ Comparison with previous model:\")\nprint(\"=\" * 60)\nprint(f\"  Previous (MiniLM):    Accuracy={0.6144:.4f}, F1={0.7611:.4f}\")\nprint(f\"  Current (JobBERT):    Accuracy={eval_result['eval_accuracy']:.4f}, F1={eval_result['eval_f1']:.4f}\")\nimprovement = (eval_result['eval_f1'] - 0.7611) / 0.7611 * 100\nprint(f\"  Improvement:          {improvement:+.2f}%\")\nprint(\"=\" * 60)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-07T17:27:48.866500Z","iopub.execute_input":"2025-12-07T17:27:48.867316Z","iopub.status.idle":"2025-12-07T17:41:36.554737Z","shell.execute_reply.started":"2025-12-07T17:27:48.867280Z","shell.execute_reply":"2025-12-07T17:41:36.553894Z"}},"outputs":[{"name":"stdout","text":" Loading dataset...\nâœ… Label distribution:\nlabel\n0    3143\n1    1556\n2    1542\nName: count, dtype: int64\nâœ… Dataset loaded: 6241 examples\n\nğŸ¤– Loading JobBERT-v3...\n","output_type":"stream"},{"name":"stderr","text":"Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at TechWolf/JobBERT-v3 and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"âœ… Model loaded successfully!\n\nğŸ”„ Tokenizing dataset...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/6241 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"59f5260d7b32469ebc56a2cf77b0a75c"}},"metadata":{}},{"name":"stdout","text":"âœ… Tokenization complete!\n\nğŸ“Š Train: 5616 | Eval: 625\n\nğŸ“ˆ Loading metrics...\n\nğŸš€ Starting JobBERT-v3 Fine-tuning...\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1053' max='1053' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1053/1053 12:40, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.883600</td>\n      <td>1.369381</td>\n      <td>0.265600</td>\n      <td>1.000000</td>\n      <td>0.265600</td>\n      <td>0.419722</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.719200</td>\n      <td>0.882879</td>\n      <td>0.641600</td>\n      <td>1.000000</td>\n      <td>0.641600</td>\n      <td>0.781676</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.594200</td>\n      <td>0.984780</td>\n      <td>0.568000</td>\n      <td>1.000000</td>\n      <td>0.568000</td>\n      <td>0.724490</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"\n============================================================\nğŸ¯ Evaluating model...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [40/40 00:08]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"\nâœ… Training completed!\n\nğŸ“Š Final Results:\n============================================================\n  Accuracy:  0.6416\n  Precision: 1.0000\n  Recall:    0.6416\n  F1-Score:  0.7817\n  Loss:      0.8829\n============================================================\n\nğŸ’¾ Saving model...\nâœ… Model saved to: ./jobbert_finetuned\n\nğŸ“ˆ Comparison with previous model:\n============================================================\n  Previous (MiniLM):    Accuracy=0.6144, F1=0.7611\n  Current (JobBERT):    Accuracy=0.6416, F1=0.7817\n  Improvement:          +2.70%\n============================================================\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"import os\nimport evaluate\nimport pandas as pd\nimport numpy as np\nimport torch\nfrom torch import nn\nfrom datasets import load_dataset, Dataset\nfrom transformers import (\n    AutoTokenizer, \n    AutoModelForSequenceClassification, \n    Trainer, \n    TrainingArguments\n)\nfrom sklearn.utils.class_weight import compute_class_weight\n\n# ØªØ¹Ø·ÙŠÙ„ WandB\nos.environ[\"WANDB_MODE\"] = \"disabled\"\n\n# ========== 1. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ==========\nprint(\"ğŸ“¥ Loading dataset...\")\ndf = pd.read_csv('/kaggle/input/train-csv/train.csv')  # Ù†Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø£ØµÙ„ÙŠ\n\ndf_clean = df[['resume_text', 'job_description_text', 'label']].copy()\n\nif df_clean['label'].dtype == 'object':\n    label_map = {\"No Fit\": 0, \"Potential Fit\": 1, \"Good Fit\": 2}\n    df_clean['label'] = df_clean['label'].map(label_map)\nelse:\n    df_clean['label'] = df_clean['label'].astype(int)\n\ndf_clean = df_clean.dropna()\n\nprint(f\"ğŸ“Š Original label distribution:\")\nprint(df_clean['label'].value_counts().sort_index())\n\n# ========== 2. Ø­Ø³Ø§Ø¨ Class Weights ==========\nlabels = df_clean['label'].values\nclass_weights = compute_class_weight(\n    class_weight='balanced',\n    classes=np.unique(labels),\n    y=labels\n)\nclass_weights_tensor = torch.tensor(class_weights, dtype=torch.float32)\n\nprint(f\"\\nâš–ï¸ Class weights calculated:\")\nfor i, weight in enumerate(class_weights):\n    print(f\"  Class {i}: {weight:.4f}\")\n\n# ========== 3. Custom Trainer Ù…Ø¹ Class Weights ==========\nclass WeightedTrainer(Trainer):\n    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n        labels = inputs.pop(\"labels\")\n        outputs = model(**inputs)\n        logits = outputs.logits\n        \n        # Ø§Ø³ØªØ®Ø¯Ø§Ù… weighted cross entropy\n        loss_fct = nn.CrossEntropyLoss(weight=class_weights_tensor.to(logits.device))\n        loss = loss_fct(logits, labels)\n        \n        return (loss, outputs) if return_outputs else loss\n\n# ========== 4. ØªØ­Ø¶ÙŠØ± Dataset ==========\ndataset = Dataset.from_pandas(df_clean[['resume_text', 'job_description_text', 'label']])\n\nprint(\"\\nğŸ¤– Loading JobBERT-v3...\")\nmodel_name = \"TechWolf/JobBERT-v3\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    model_name, \n    num_labels=3,\n    ignore_mismatched_sizes=True\n)\n\n# ========== 5. Tokenization ==========\nprint(\"\\nğŸ”„ Tokenizing...\")\ndef tokenize_function(examples):\n    return tokenizer(\n        examples['resume_text'],\n        examples['job_description_text'],\n        truncation=True,\n        padding='max_length',\n        max_length=256\n    )\n\ntokenized_dataset = dataset.map(\n    tokenize_function, \n    batched=True, \n    remove_columns=['resume_text', 'job_description_text']\n)\n\n# ========== 6. Split Data ==========\ntrain_size = int(0.9 * len(tokenized_dataset))\ntrain_dataset = tokenized_dataset.select(range(train_size))\neval_dataset = tokenized_dataset.select(range(train_size, len(tokenized_dataset)))\n\nprint(f\"\\nğŸ“Š Train: {len(train_dataset)} | Eval: {len(eval_dataset)}\")\n\n# ========== 7. Metrics ==========\naccuracy_metric = evaluate.load(\"accuracy\")\nprecision_metric = evaluate.load(\"precision\")\nrecall_metric = evaluate.load(\"recall\")\nf1_metric = evaluate.load(\"f1\")\n\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    preds = logits.argmax(axis=-1)\n    \n    # Ù†Ø³ØªØ®Ø¯Ù… sklearn Ù…Ø¨Ø§Ø´Ø±Ø© Ø¹Ù„Ø´Ø§Ù† ÙÙŠÙ‡Ø§ zero_division\n    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n    \n    return {\n        \"accuracy\": accuracy_score(labels, preds),\n        \"precision\": precision_score(labels, preds, average=\"weighted\", zero_division=0),\n        \"recall\": recall_score(labels, preds, average=\"weighted\", zero_division=0),\n        \"f1\": f1_score(labels, preds, average=\"weighted\", zero_division=0),\n        \"f1_macro\": f1_score(labels, preds, average=\"macro\", zero_division=0),\n    }\n\n# ========== 8. Training Arguments (Ù…Ø­Ø³Ù‘Ù†Ø©) ==========\ntry:\n    training_args = TrainingArguments(\n        output_dir=\"./jobbert_balanced_results\",\n        eval_strategy=\"epoch\",\n        learning_rate=3e-5,  # Ø²ÙˆØ¯Ù†Ø§ Ø´ÙˆÙŠØ©\n        per_device_train_batch_size=8,\n        per_device_eval_batch_size=8,\n        num_train_epochs=5,  # Ø²ÙˆØ¯Ù†Ø§ Ø§Ù„Ù€ epochs\n        weight_decay=0.01,\n        save_strategy=\"epoch\",\n        logging_steps=50,\n        report_to=\"none\",\n        save_total_limit=2,\n        load_best_model_at_end=True,\n        metric_for_best_model=\"f1_macro\",  # Ù†Ø³ØªØ®Ø¯Ù… macro F1\n        warmup_steps=100,  # learning rate warmup\n    )\nexcept TypeError:\n    training_args = TrainingArguments(\n        output_dir=\"./jobbert_balanced_results\",\n        evaluation_strategy=\"epoch\",\n        learning_rate=3e-5,\n        per_device_train_batch_size=8,\n        per_device_eval_batch_size=8,\n        num_train_epochs=5,\n        weight_decay=0.01,\n        save_strategy=\"epoch\",\n        logging_steps=50,\n        report_to=\"none\",\n        save_total_limit=2,\n        load_best_model_at_end=True,\n        metric_for_best_model=\"f1_macro\",\n        warmup_steps=100,\n    )\n\n# ========== 9. Weighted Trainer ==========\ntrainer = WeightedTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=eval_dataset,\n    compute_metrics=compute_metrics\n)\n\n# ========== 10. Training ==========\nprint(\"\\nğŸš€ Starting Balanced Fine-tuning...\")\nprint(\"=\" * 60)\ntrainer.train()\n\n# ========== 11. Evaluation ==========\nprint(\"\\n\" + \"=\" * 60)\nprint(\"ğŸ¯ Final Evaluation...\")\neval_result = trainer.evaluate()\n\n# ========== 12. ØªØ­Ù„ÙŠÙ„ Ù…ÙØµÙ„ Ù„Ù„Ù†ØªØ§Ø¦Ø¬ ==========\nprint(\"\\nâœ… Training completed!\")\nprint(\"\\nğŸ“Š Final Results:\")\nprint(\"=\" * 60)\nprint(f\"  Accuracy:        {eval_result['eval_accuracy']:.4f}\")\nprint(f\"  Precision:       {eval_result['eval_precision']:.4f}\")\nprint(f\"  Recall:          {eval_result['eval_recall']:.4f}\")\nprint(f\"  F1 (weighted):   {eval_result['eval_f1']:.4f}\")\nprint(f\"  F1 (macro):      {eval_result['eval_f1_macro']:.4f}\")\nprint(f\"  Loss:            {eval_result['eval_loss']:.4f}\")\nprint(\"=\" * 60)\n\n# ========== 13. ØªØ­Ù„ÙŠÙ„ predictions ==========\nprint(\"\\nğŸ” Analyzing predictions per class...\")\npredictions = trainer.predict(eval_dataset)\npreds = predictions.predictions.argmax(axis=-1)\ntrue_labels = predictions.label_ids\n\nfrom sklearn.metrics import classification_report, confusion_matrix\n\nprint(\"\\nğŸ“‹ Classification Report:\")\nprint(classification_report(true_labels, preds, \n                          target_names=['No Fit', 'Potential Fit', 'Good Fit'],\n                          zero_division=0))\n\nprint(\"\\nğŸ¯ Confusion Matrix:\")\ncm = confusion_matrix(true_labels, preds)\nprint(\"          Predicted\")\nprint(\"           0    1    2\")\nfor i, row in enumerate(cm):\n    print(f\"Actual {i}: {row}\")\n\n# ========== 14. Save Model ==========\nprint(\"\\nğŸ’¾ Saving model...\")\nmodel.save_pretrained(\"./jobbert_balanced_finetuned\")\ntokenizer.save_pretrained(\"./jobbert_balanced_finetuned\")\nprint(\"âœ… Model saved!\")\n\n# ========== 15. Ù…Ù‚Ø§Ø±Ù†Ø© Ø´Ø§Ù…Ù„Ø© ==========\nprint(\"\\nğŸ“ˆ Complete Comparison:\")\nprint(\"=\" * 60)\nprint(f\"  MiniLM (baseline):   Acc={0.6144:.4f}, F1={0.7611:.4f}\")\nprint(f\"  JobBERT (basic):     Acc={0.6416:.4f}, F1={0.7817:.4f}\")\nprint(f\"  JobBERT (balanced):  Acc={eval_result['eval_accuracy']:.4f}, F1={eval_result['eval_f1']:.4f}\")\nprint(\"=\" * 60)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T18:03:16.670929Z","iopub.execute_input":"2025-12-07T18:03:16.671256Z","iopub.status.idle":"2025-12-07T18:25:48.338608Z","shell.execute_reply.started":"2025-12-07T18:03:16.671230Z","shell.execute_reply":"2025-12-07T18:25:48.337711Z"}},"outputs":[{"name":"stdout","text":"ğŸ“¥ Loading dataset...\nğŸ“Š Original label distribution:\nlabel\n0    3143\n1    1556\n2    1542\nName: count, dtype: int64\n\nâš–ï¸ Class weights calculated:\n  Class 0: 0.6619\n  Class 1: 1.3370\n  Class 2: 1.3491\n\nğŸ¤– Loading JobBERT-v3...\n","output_type":"stream"},{"name":"stderr","text":"Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at TechWolf/JobBERT-v3 and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\nğŸ”„ Tokenizing...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/6241 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"03d38c8a88144d66b89a951379612e0e"}},"metadata":{}},{"name":"stdout","text":"\nğŸ“Š Train: 5616 | Eval: 625\n\nğŸš€ Starting Balanced Fine-tuning...\n============================================================\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1755' max='1755' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1755/1755 21:20, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n      <th>F1 Macro</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.891500</td>\n      <td>1.008316</td>\n      <td>0.590400</td>\n      <td>1.000000</td>\n      <td>0.590400</td>\n      <td>0.742455</td>\n      <td>0.247485</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.745700</td>\n      <td>0.748240</td>\n      <td>0.790400</td>\n      <td>1.000000</td>\n      <td>0.790400</td>\n      <td>0.882931</td>\n      <td>0.294310</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.635600</td>\n      <td>0.761987</td>\n      <td>0.732800</td>\n      <td>1.000000</td>\n      <td>0.732800</td>\n      <td>0.845799</td>\n      <td>0.281933</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.556400</td>\n      <td>0.711983</td>\n      <td>0.731200</td>\n      <td>1.000000</td>\n      <td>0.731200</td>\n      <td>0.844732</td>\n      <td>0.281577</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.439000</td>\n      <td>0.765438</td>\n      <td>0.704000</td>\n      <td>1.000000</td>\n      <td>0.704000</td>\n      <td>0.826291</td>\n      <td>0.275430</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"\n============================================================\nğŸ¯ Final Evaluation...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"\nâœ… Training completed!\n\nğŸ“Š Final Results:\n============================================================\n  Accuracy:        0.7904\n  Precision:       1.0000\n  Recall:          0.7904\n  F1 (weighted):   0.8829\n  F1 (macro):      0.2943\n  Loss:            0.7482\n============================================================\n\nğŸ” Analyzing predictions per class...\n\nğŸ“‹ Classification Report:\n               precision    recall  f1-score   support\n\n       No Fit       0.00      0.00      0.00         0\nPotential Fit       0.00      0.00      0.00         0\n     Good Fit       1.00      0.79      0.88       625\n\n     accuracy                           0.79       625\n    macro avg       0.33      0.26      0.29       625\n weighted avg       1.00      0.79      0.88       625\n\n\nğŸ¯ Confusion Matrix:\n          Predicted\n           0    1    2\nActual 0: [0 0 0]\nActual 1: [0 0 0]\nActual 2: [ 95  36 494]\n\nğŸ’¾ Saving model...\nâœ… Model saved!\n\nğŸ“ˆ Complete Comparison:\n============================================================\n  MiniLM (baseline):   Acc=0.6144, F1=0.7611\n  JobBERT (basic):     Acc=0.6416, F1=0.7817\n  JobBERT (balanced):  Acc=0.7904, F1=0.8829\n============================================================\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}