{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12964026,"sourceType":"datasetVersion","datasetId":8204825}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# CV–Job Matching with BGE + LoRA Fine-Tuning  \n\n**Purpose:**  \nThis notebook matches CVs/resumes with job descriptions using a fine-tuned version of [BAAI/bge-large-en-v1.5](https://huggingface.co/BAAI/bge-large-en-v1.5) (a high-quality sentence embedding model).  \nIt loads the base BGE model and applies a LoRA adapter (`shashu2325/resume-job-matcher-lora`) to specialize the embeddings for resume–job relevance.  \n\n**Modes:**  \n\n- **Single CV–Job Mode**: Computes similarity and a match score between one CV/resume and one job description.  \n- **Batch Matching Mode** *(optional extension)*: Encodes multiple CVs and multiple job descriptions, then builds a similarity matrix to find top matches.  \n\n**Inputs:**  \n- `resume.txt` : text file containing one or more CVs/resumes.  \n- `job_desc.txt` : text file containing one or more job descriptions.  \n\n**Outputs:**  \n- **Match Score** (single mode): cosine similarity normalized and mapped to a 0–1 “suitability” score.  \n- **Similarity Matrix** and **Top Matches** (batch mode).  \n\n**How It Works:**  \n1. Load the base model and LoRA adapter.  \n2. Tokenize the input texts (up to 512 tokens).  \n3. Pass through the model to get contextual embeddings.  \n4. Apply mean pooling over the token embeddings.  \n5. L2-normalize both embeddings and compute similarity.  \n6. Convert similarity to a “match score” with a sigmoid.  \n\n**Usage:**  \nRun the cells sequentially.  \n- For **single CV–job** matching: provide the file paths or paste text into the variables.  \n- For **batch matching**: loop through multiple CVs and job descriptions, encode each, and compute the similarity matrix.  \n","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModel, AutoTokenizer\nfrom peft import PeftModel\nimport torch\nimport torch.nn.functional as F\n\n# Load models\nbase_model = AutoModel.from_pretrained(\"BAAI/bge-large-en-v1.5\")\nmodel = PeftModel.from_pretrained(base_model, \"shashu2325/resume-job-matcher-lora\")\ntokenizer = AutoTokenizer.from_pretrained(\"BAAI/bge-large-en-v1.5\")\n\n# Example texts\n# resume_text = \"Software engineer with Python experience\"\n# job_text = \"Looking for Python developer\"\nresume_text = open(\"/kaggle/input/resjob/resume.txt\").read()\njob_text = open(\"/kaggle/input/resjob/job_desc.txt\").read()\n\n# resume_inputs = model.encode(resume_text, convert_to_tensor=True)\n# job_inputs = model.encode(jd_text, convert_to_tensor=True)\n# Process texts\nresume_inputs = tokenizer(resume_text, return_tensors=\"pt\", max_length=512, padding=\"max_length\", truncation=True)\njob_inputs = tokenizer(job_text, return_tensors=\"pt\", max_length=512, padding=\"max_length\", truncation=True)\n\n# Get embeddings\nwith torch.no_grad():\n    # Get embeddings using mean pooling\n    resume_outputs = model(**resume_inputs)\n    job_outputs = model(**job_inputs)\n    \n    # Mean pooling\n    resume_emb = resume_outputs.last_hidden_state.mean(dim=1)\n    job_emb = job_outputs.last_hidden_state.mean(dim=1)\n    \n    # Normalize and calculate similarity\n    resume_emb = F.normalize(resume_emb, p=2, dim=1)\n    job_emb = F.normalize(job_emb, p=2, dim=1)\n    \n    similarity = torch.sum(resume_emb * job_emb, dim=1)\n    match_score = torch.sigmoid(similarity).item()\n\nprint(f\"Match score: {match_score:.4f}\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-16T08:18:40.653515Z","iopub.execute_input":"2025-09-16T08:18:40.654352Z","iopub.status.idle":"2025-09-16T08:18:53.661404Z","shell.execute_reply.started":"2025-09-16T08:18:40.654311Z","shell.execute_reply":"2025-09-16T08:18:53.660209Z"}},"outputs":[{"name":"stdout","text":"Match score: 0.6401\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}